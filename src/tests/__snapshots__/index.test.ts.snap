// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`Lexer > handle whitespace and newline correctly 1`] = `
{
  "Groups": [
    {
      "groupIndex": -1,
      "name": "SkipGroup",
      "tokenIndexs": Set {
        3,
      },
      "tokens": [
        {
          "name": "WhiteSpace",
          "pattern": /\\\\s\\+/,
          "tokenIndex": 3,
        },
      ],
    },
  ],
  "errors": [],
  "tokens": [
    {
      "endColumn": 3,
      "endOffset": 2,
      "image": "let",
      "line": 1,
      "startColumn": 1,
      "startOffset": 0,
      "tokenType": {
        "name": "Let",
        "pattern": /let/,
        "tokenIndex": 0,
      },
    },
    {
      "endColumn": 12,
      "endOffset": 11,
      "image": "myVar",
      "line": 1,
      "startColumn": 8,
      "startOffset": 7,
      "tokenType": {
        "name": "Identifier",
        "pattern": /\\[a-zA-Z_\\]\\\\w\\*/,
        "tokenIndex": 1,
      },
    },
    {
      "endColumn": 6,
      "endOffset": 18,
      "image": "number",
      "line": 2,
      "startColumn": 1,
      "startOffset": 13,
      "tokenType": {
        "name": "Typenumber",
        "pattern": /number/,
        "tokenIndex": 4,
      },
    },
    {
      "endColumn": 7,
      "endOffset": 19,
      "image": "<EOF>",
      "line": 2,
      "startColumn": 7,
      "startOffset": 19,
      "tokenType": {
        "name": "<EOF>",
        "pattern": /<EOF>/,
        "tokenIndex": -1,
      },
    },
  ],
}
`;

exports[`Lexer > tokenize report invalid character 1`] = `
{
  "Groups": [
    {
      "groupIndex": -1,
      "name": "SkipGroup",
      "tokenIndexs": Set {
        3,
      },
      "tokens": [
        {
          "name": "WhiteSpace",
          "pattern": /\\\\s\\+/,
          "tokenIndex": 3,
        },
      ],
    },
  ],
  "errors": [
    {
      "Offset": 4,
      "column": 5,
      "line": 1,
      "message": "Unexpected character '~'",
    },
  ],
  "tokens": [
    {
      "endColumn": 3,
      "endOffset": 2,
      "image": "let",
      "line": 1,
      "startColumn": 1,
      "startOffset": 0,
      "tokenType": {
        "name": "Let",
        "pattern": /let/,
        "tokenIndex": 0,
      },
    },
    {
      "endColumn": 6,
      "endOffset": 5,
      "image": "<EOF>",
      "line": 1,
      "startColumn": 6,
      "startOffset": 5,
      "tokenType": {
        "name": "<EOF>",
        "pattern": /<EOF>/,
        "tokenIndex": -1,
      },
    },
  ],
}
`;

exports[`Lexer > tokenize successfully 1`] = `
{
  "Groups": [
    {
      "groupIndex": -1,
      "name": "SkipGroup",
      "tokenIndexs": Set {
        3,
      },
      "tokens": [
        {
          "name": "WhiteSpace",
          "pattern": /\\\\s\\+/,
          "tokenIndex": 3,
        },
      ],
    },
  ],
  "errors": [],
  "tokens": [
    {
      "endColumn": 3,
      "endOffset": 2,
      "image": "let",
      "line": 1,
      "startColumn": 1,
      "startOffset": 0,
      "tokenType": {
        "name": "Let",
        "pattern": /let/,
        "tokenIndex": 0,
      },
    },
    {
      "endColumn": 8,
      "endOffset": 7,
      "image": "test",
      "line": 1,
      "startColumn": 5,
      "startOffset": 4,
      "tokenType": {
        "name": "Identifier",
        "pattern": /\\[a-zA-Z_\\]\\\\w\\*/,
        "tokenIndex": 1,
      },
    },
    {
      "endColumn": 9,
      "endOffset": 8,
      "image": "<EOF>",
      "line": 1,
      "startColumn": 9,
      "startOffset": 8,
      "tokenType": {
        "name": "<EOF>",
        "pattern": /<EOF>/,
        "tokenIndex": -1,
      },
    },
  ],
}
`;

exports[`Parser > should parse let statement with type correctly 1`] = `
{
  "ErrorStateStack": [],
  "StateStack": [
    0,
    1,
  ],
  "cst": {
    "CstType": "Node",
    "children": [
      {
        "CstType": "TokenNode",
        "EndColumn": 3,
        "EndOffset": 2,
        "StartColumn": 1,
        "StartOffset": 0,
        "image": "let",
        "line": 1,
        "tokenIdx": 0,
        "type": "Let",
      },
      {
        "CstType": "TokenNode",
        "EndColumn": 9,
        "EndOffset": 8,
        "StartColumn": 5,
        "StartOffset": 4,
        "image": "myVar",
        "line": 1,
        "tokenIdx": 1,
        "type": "Identifier",
      },
      {
        "CstType": "TokenNode",
        "EndColumn": 16,
        "EndOffset": 15,
        "StartColumn": 11,
        "StartOffset": 10,
        "image": "number",
        "line": 1,
        "tokenIdx": 4,
        "type": "Typenumber",
      },
    ],
    "type": "Main",
  },
  "errors": [],
}
`;

exports[`Parser > should parse simple let statement 1`] = `
{
  "ErrorStateStack": [],
  "StateStack": [
    0,
    1,
  ],
  "cst": {
    "CstType": "Node",
    "children": [
      {
        "CstType": "TokenNode",
        "EndColumn": 3,
        "EndOffset": 2,
        "StartColumn": 1,
        "StartOffset": 0,
        "image": "let",
        "line": 1,
        "tokenIdx": 0,
        "type": "Let",
      },
      {
        "CstType": "TokenNode",
        "EndColumn": 8,
        "EndOffset": 7,
        "StartColumn": 5,
        "StartOffset": 4,
        "image": "test",
        "line": 1,
        "tokenIdx": 1,
        "type": "Identifier",
      },
    ],
    "type": "Main",
  },
  "errors": [],
}
`;

exports[`Parser > should report syntax error if type is missing 1`] = `
{
  "ErrorStateStack": [
    0,
    2,
    3,
  ],
  "StateStack": [
    0,
    2,
    3,
  ],
  "cst": {
    "CstType": "TokenNode",
    "EndColumn": 3,
    "EndOffset": 2,
    "StartColumn": 1,
    "StartOffset": 0,
    "image": "let",
    "line": 1,
    "tokenIdx": 0,
    "type": "Let",
  },
  "errors": [
    {
      "ExpectedTokens": [
        "Typenumber",
        "Typestring",
      ],
      "endColumn": 10,
      "found": "<EOF>",
      "line": 1,
      "startColumn": 10,
    },
  ],
}
`;

exports[`Parser Table > successfully 1`] = `
{
  "ActionTable": {
    "0": {
      "0": {
        "to": 2,
        "type": "shift",
      },
    },
    "1": {
      "-1": {
        "type": "accept",
      },
    },
    "2": {
      "1": {
        "to": 3,
        "type": "shift",
      },
    },
    "3": {
      "4": {
        "to": 4,
        "type": "shift",
      },
      "5": {
        "to": 5,
        "type": "shift",
      },
    },
    "4": {
      "-1": {
        "prod": 1,
        "type": "reduce",
      },
    },
    "5": {
      "-1": {
        "prod": 2,
        "type": "reduce",
      },
    },
  },
  "GotoTable": {
    "0": {
      "10000": 1,
    },
    "1": {},
    "2": {},
    "3": {},
    "4": {},
    "5": {},
  },
  "States": [
    {
      "items": [
        {
          "dot": 0,
          "lookaheads": Set {
            -1,
          },
          "productionIdx": 0,
        },
        {
          "dot": 0,
          "lookaheads": Set {
            -1,
          },
          "productionIdx": 1,
        },
        {
          "dot": 0,
          "lookaheads": Set {
            -1,
          },
          "productionIdx": 2,
        },
      ],
      "transitions": Map {
        10000 => 1,
        0 => 2,
      },
    },
    {
      "items": [
        {
          "dot": 1,
          "lookaheads": Set {
            -1,
          },
          "productionIdx": 0,
        },
      ],
      "transitions": Map {},
    },
    {
      "items": [
        {
          "dot": 1,
          "lookaheads": Set {
            -1,
          },
          "productionIdx": 1,
        },
        {
          "dot": 1,
          "lookaheads": Set {
            -1,
          },
          "productionIdx": 2,
        },
      ],
      "transitions": Map {
        1 => 3,
      },
    },
    {
      "items": [
        {
          "dot": 2,
          "lookaheads": Set {
            -1,
          },
          "productionIdx": 1,
        },
        {
          "dot": 2,
          "lookaheads": Set {
            -1,
          },
          "productionIdx": 2,
        },
      ],
      "transitions": Map {
        4 => 4,
        5 => 5,
      },
    },
    {
      "items": [
        {
          "dot": 3,
          "lookaheads": Set {
            -1,
          },
          "productionIdx": 1,
        },
      ],
      "transitions": Map {},
    },
    {
      "items": [
        {
          "dot": 3,
          "lookaheads": Set {
            -1,
          },
          "productionIdx": 2,
        },
      ],
      "transitions": Map {},
    },
  ],
  "TokenMap": {
    "-1": "EOF",
    "0": "Let",
    "1": "Identifier",
    "2": "NumberLiteral",
    "3": "WhiteSpace",
    "4": "Typenumber",
    "5": "Typestring",
  },
  "nonterminalMap": {
    "Main": 10000,
  },
  "productions": [
    {
      "body": [
        10000,
      ],
      "head": "S'",
    },
    {
      "body": [
        0,
        1,
        4,
      ],
      "head": "Main",
    },
    {
      "body": [
        0,
        1,
        5,
      ],
      "head": "Main",
    },
  ],
}
`;
